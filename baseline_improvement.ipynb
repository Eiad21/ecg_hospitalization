{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a009e439-1f57-4e04-883c-e743671f39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a14fad1-54b2-4268-aefe-373cf17fe345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff34e9d-cdb9-4f06-89ec-30f2d748cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "csv_path = 'D:\\Omar\\Friends\\European_HealthCare_Hackathon\\ecg_hospitalization\\data\\processed\\meta\\data_pairs.csv'  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9cd9d7-fa4e-4f70-a2f1-d739df090de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>np_file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231122_211154_57000.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231122_221512_86000.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231122_222724_38000.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231122_101126_09000.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231120_222227_88000.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23287</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231120_184943_05000.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23288</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231122_222459_73000.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23289</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231120_101111_35000.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23290</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231122_210819_41000.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23291</th>\n",
       "      <td>data\\processed\\npy\\MUSE_20231121_125151_04000.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23292 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            np_file_path  label\n",
       "0      data\\processed\\npy\\MUSE_20231122_211154_57000.npy      0\n",
       "1      data\\processed\\npy\\MUSE_20231122_221512_86000.npy      0\n",
       "2      data\\processed\\npy\\MUSE_20231122_222724_38000.npy      0\n",
       "3      data\\processed\\npy\\MUSE_20231122_101126_09000.npy      1\n",
       "4      data\\processed\\npy\\MUSE_20231120_222227_88000.npy      0\n",
       "...                                                  ...    ...\n",
       "23287  data\\processed\\npy\\MUSE_20231120_184943_05000.npy      0\n",
       "23288  data\\processed\\npy\\MUSE_20231122_222459_73000.npy      0\n",
       "23289  data\\processed\\npy\\MUSE_20231120_101111_35000.npy      0\n",
       "23290  data\\processed\\npy\\MUSE_20231122_210819_41000.npy      0\n",
       "23291  data\\processed\\npy\\MUSE_20231121_125151_04000.npy      1\n",
       "\n",
       "[23292 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "881e3b13-3c96-42e4-8710-88fe138053f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store data\n",
    "data_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ccff7-d3d4-449e-ab93-b6ce2db7acb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8906b31f-fea9-49b1-bbf8-e77f141e5b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through rows and load .npy files\n",
    "for index, row in df.iterrows():\n",
    "    file_path = row['np_file_path']\n",
    "    label = row['label']\n",
    "\n",
    "    # Load the .npy file\n",
    "    loaded_data = np.load(file_path)\n",
    "\n",
    "    # Append the loaded data and label to the lists\n",
    "    data_list.append(loaded_data)\n",
    "    labels_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f93a28-59d0-41ff-a237-24e3c67b12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "data_array = np.array(data_list)\n",
    "labels_array = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f005fab-7fdb-45df-bd41-d77e5b725881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes for verification\n",
    "print(\"Data Array Shape:\", data_array.shape)\n",
    "print(\"Labels Array Shape:\", labels_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adeab7b-b6ad-4fa1-a646-cfe5c5157d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "#csv_path = 'your_file.csv'  # Replace with the path to your CSV file\n",
    "#df = pd.read_csv(csv_path, header=None, names=['np_file_path', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17858df-34cc-4d8a-a140-7255c1650903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy import signal\n",
    "from scipy.fft import fft\n",
    "from biosppy.signals import ecg  # Biosppy is a library for biosignal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64880d9f-4557-40aa-8b05-69ac95363ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e48a5-37ac-4b87-bcb0-5a17541aa828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in binary read mode ('rb') to unpickle the data\n",
    "#with open('batch_of_data.pickle', 'rb') as file:\n",
    "#    loaded__data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447608b-c80f-4e37-bf23-cf81ed21896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ecg_data = []\n",
    "#for patient in loaded_data:\n",
    "#    new_patient_format = np.array(list(patient.values()))\n",
    "#    ecg_data.append(new_patient_format)\n",
    "#    print(len(new_patient_format[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de51f51-c5b4-4618-bbab-98dc28cd4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ecg_data = np.array(ecg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe431c47-d8d6-4cce-b69d-4342110f4031",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data = data_array\n",
    "labels = labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2186c0-3f9e-4bba-9c94-001b4b0745ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patients = 23292\n",
    "num_leads = 8\n",
    "num_time_points = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a29ea-6b8c-4b0c-bfb2-f1ed28099ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(42)\n",
    "#ecg_data = np.random.randn(num_patients, num_leads, num_time_points)\n",
    "#labels = np.random.randint(0, 3, size=num_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b12fe7-a437-4beb-b06b-60ca2fa4673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900bb2c-72d4-48f3-90ec-bb8b42b09301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from each lead\n",
    "def extract_features(lead):\n",
    "    # 1. Statistical Features\n",
    "    mean_value = np.mean(lead)\n",
    "#    print('mean_value :', mean_value)\n",
    "    median_value = np.median(lead)\n",
    "#    print('median_value :', median_value)\n",
    "    std_dev_value = np.std(lead)\n",
    "#    print('std_dev_value :', std_dev_value)\n",
    "    skewness_value = skew(lead)\n",
    "#    print('skewness_value :', skewness_value)\n",
    "    kurtosis_value = kurtosis(lead)\n",
    "#    print('kurtosis_value :', kurtosis_value)\n",
    "\n",
    "    # 2. Time-Domain Features\n",
    "    # You might need to preprocess the data to find R-peaks for RR interval calculations\n",
    "    # Example using biosppy\n",
    "#    rpeaks = ecg.ecg(lead, sampling_rate=500, show=False)['rpeaks']\n",
    "   # _, rpeaks = ecg.ecg(lead, sampling_rate=500, show=False)\n",
    "#    print(\"YES\")\n",
    "#    rr_interval = np.diff(rpeaks)\n",
    "\n",
    "    # Calculate features from RR intervals\n",
    "#    rr_mean = np.mean(rr_interval)\n",
    "#    print('rr_mean :', rr_mean)    \n",
    "#    heart_rate = 60 / rr_mean\n",
    "\n",
    "    # 3. Frequency-Domain Features\n",
    "    #power_spectral_density (psd) shape is (num_time_points // 2 + 1)\n",
    "    f, psd = signal.welch(lead, fs=500)\n",
    "    dominant_frequency = f[np.argmax(psd)]\n",
    "#    print('dominant_frequency :', dominant_frequency)\n",
    "    spectral_entropy = -np.sum(psd * np.log2(psd + 1e-10))\n",
    "#    print('spectral_entropy :', spectral_entropy)\n",
    "    \n",
    "    # 4. Wavelet Transform (using PyWavelets library)\n",
    "    # Wavelet Transform Features\n",
    "#    coeffs = pywt.wavedec(lead, 'db1', level=4)\n",
    "#    print('coeffs :', coeffs)    \n",
    "\n",
    "    # Combine all features into a single array\n",
    "    extracted_features = np.array([\n",
    "        mean_value, median_value, std_dev_value, skewness_value, kurtosis_value,\n",
    "        dominant_frequency, spectral_entropy\n",
    "#        *coeffs[0], *coeffs[1], *coeffs[2], *coeffs[3]\n",
    "    ])\n",
    "\n",
    "    return extracted_features\n",
    "\n",
    "#    (cA, cD) = pywt.dwt(lead, 'db1')\n",
    "\n",
    "    # 5. Heart Rate Variability Features\n",
    "    # Already calculated RR intervals, you can extract various features from them\n",
    "\n",
    "    # 6. Dynamical Features\n",
    "    # You might need a dynamic model or use dynamic time warping techniques\n",
    "\n",
    "    # 7. Deep Learning Representations\n",
    "    # Use pre-trained models or train your own CNN/RNN on ECG data\n",
    "\n",
    "    # 8. Principal Component Analysis (PCA)\n",
    "#    from sklearn.decomposition import PCA\n",
    "\n",
    "#    flattened_data = np.reshape(ecg_data, (num_patients, -1))\n",
    "#    pca = PCA(n_components=10)  # Adjust the number of components\n",
    "#    pca_features = pca.fit_transform(flattened_data)\n",
    "    \n",
    "    # 9. Cross-Lead Features\n",
    "#    lead_correlations = np.zeros((num_patients, num_leads, num_leads))\n",
    "#    for i in range(num_patients):\n",
    "#        for j in range(num_leads):\n",
    "#            for k in range(num_leads):\n",
    "#                lead_correlations[i, j, k] = np.corrcoef(ecg_data[i, j, :], ecg_data[i, k, :])[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834543da-b11b-48dd-8aae-d8fcb1ba3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(extract_features(ecg_data[0, 0, :]))\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ffb55-abd4-49e9-9b19-0bcaf8303c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty array to store features for each patient\n",
    "num_features = len(extract_features(ecg_data[0, 0, :]))\n",
    "patient_features = np.zeros((num_patients, num_features * num_leads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a19cff-b54c-4425-a24c-c6fc2dc28274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature extraction for each lead and concatenate features for each patient\n",
    "for patient_index in tqdm(range(num_patients)):\n",
    "    patient_lead_features = np.zeros((num_leads, len(extract_features(ecg_data[0, 0, :]))))\n",
    "    \n",
    "    for lead_index in range(num_leads):\n",
    "        patient_lead_features[lead_index, :] = extract_features(ecg_data[patient_index, lead_index, :])\n",
    "    \n",
    "    # Concatenate features for the current patient\n",
    "    patient_features[patient_index, :] = patient_lead_features.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558919b1-de4a-4fed-9f79-a2503ef36902",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce450d-704b-43f6-b2b2-d020a80618de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a958a6b-8d26-460c-adf3-759f34ff0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(patient_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1354d-20eb-4a38-8c15-f62bd8e5c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367d043-9e8d-4c67-aff6-1df5665ce803",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = data_frame.isna().sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of NaN values for each column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c8a4b-96f9-42e8-b202-6e6318fc3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_nans = data_frame.index[data_frame.isnull().any(axis=1)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed02e49-fefa-412a-ac26-0395ccc5fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78544c9d-ef38-4902-9799-339ea3d597f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[np.logical_not(np.isin(np.arange(len(y)), indices_with_nans))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c7fa0-ef7a-4563-85ea-c0213f8bf4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = data_frame.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb1c7b-a83f-437a-9c3d-9176188562f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = df_cleaned.isna().sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of NaN values for each column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349ed88-15f3-4ff8-a735-f43c4bde0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_features = df_cleaned.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb750f-be35-4ede-859b-95c9528d44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming patient_features is your 2D array of features (patients x features)\n",
    "# Assuming y is your target labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(patient_features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e943d-1133-4c29-a8d3-622c23322fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18d588-5f1c-4cf8-ba6a-0ac8a80e07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42b39c-2042-4d82-93ef-47ee5f445d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices of non-null values\n",
    "#non_null_indices = ~np.isnan(X_train_scaled)\n",
    "\n",
    "# Filter the array to remove null values\n",
    "#X_train_scaled = X_train_scaled[non_null_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9385cc-e9e8-4ffe-a70e-887080b56317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices of non-null values\n",
    "#non_null_indices = ~np.isnan(X_test_scaled)\n",
    "\n",
    "# Filter the array to remove null values\n",
    "#X_test_scaled = X_test_scaled[non_null_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f47bf-d402-437e-99b0-2a58387fb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdddfcf-6508-45a9-97b2-08699461ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b30feb-0c30-453c-a632-907b074a4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c45c1-a351-442d-b595-54f232cbbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eddabdd-5a19-4ef6-98af-cdb628126547",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.count_nonzero(y == 0)\n",
    "count / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c095c5-a0dc-4cb5-88fb-25876f4edcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.count_nonzero(y == 1)\n",
    "count / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5cbb2-854b-4f23-9ecf-92d2463ac2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.count_nonzero(y == 2)\n",
    "count / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7406940-9cfc-4706-9124-b57cdabacf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
